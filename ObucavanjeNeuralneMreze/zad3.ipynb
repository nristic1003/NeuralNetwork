{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from random import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.io\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "with open(\"letter-recognition.data\") as myfile:\n",
    "    data = myfile.read()\n",
    "\n",
    "label = []\n",
    "data = data.splitlines()\n",
    "for i in range(len(data)):\n",
    "    data[i] = data[i].split(\",\")\n",
    "    label.append(data[i][:1])\n",
    "    data[i] = data[i][1:]\n",
    "data = np.array(data)\n",
    "data = data.astype(int)\n",
    "\n",
    "num_letters = np.zeros(26)\n",
    "for i in range(len(label)):\n",
    "    label[i] = ord(label[i][0]) - 65\n",
    "    num_letters[label[i]] += 1\n",
    "label = np.array(label)\n",
    "label = to_categorical(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pos = np.arange(26)\n",
    "objects = map(chr, range(65, 91))\n",
    "plt.bar(y_pos, num_letters, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Broj Slova')\n",
    "plt.title('Podela podataka')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = preprocessing.scale(data)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, label, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struktura = np.array([[10,15] , [20,50,10]])\n",
    "regularizacija = np.array([0.1 , 0.25, 0.5, 0.7])\n",
    "tezine = np.array([2, 3, 4])\n",
    "fje = np.array(['tanh' , 'relu' , 'sigmoid'])\n",
    "maxacc = 0 \n",
    "history = 0\n",
    "arg = []\n",
    "t = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stru in struktura:\n",
    "    for reg in regularizacija:\n",
    "        for tez in tezine:\n",
    "            for f in fje:\n",
    "                model = keras.Sequential()\n",
    "                \n",
    "                model.add(keras.layers.Dense(stru[0], input_shape = (16,), activation = f , kernel_regularizer=keras.regularizers.l2(l=reg)))\n",
    "                for i in range(len(stru)-1):\n",
    "                    model.add(keras.layers.Dense(stru[i+1], activation = f , kernel_regularizer=keras.regularizers.l2(l=reg)))\n",
    "                    b = [tez] * stru[i+1]\n",
    "                    w = [b] * stru[i]\n",
    "                    w = np.array(w)\n",
    "                    b = np.zeros(stru[i+1])\n",
    "                    model.layers[i+1].set_weights([w,b])\n",
    "                \n",
    "                earlystopper = EarlyStopping(monitor='val_loss', min_delta=4, patience=10, verbose=1, mode='auto')\n",
    "                model.add(keras.layers.Dense(26, activation = \"softmax\"))     \n",
    "                model.compile(optimizer = \"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                hist = model.fit(x_train, y_train, epochs = 300, validation_split = 0.15, batch_size = 800, verbose = 0,callbacks = [earlystopper])\n",
    "                loss, acc = model.evaluate(x_test, y_test, verbose = 0)\n",
    "                if(acc > maxacc):\n",
    "                    maxacc=acc\n",
    "                    arg = [stru, reg, tez, f, loss, acc]\n",
    "                    history = hist\n",
    "                print(t,acc)\n",
    "                t = t+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict=history.history\n",
    "\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values=history_dict['val_loss']\n",
    "plt.figure()\n",
    "plt.figure()\n",
    "plt.plot(loss_values,'b',label='training loss')\n",
    "plt.plot(val_loss_values,'r',label='val training loss')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_values = history_dict['accuracy']\n",
    "val_accuracy_values=history_dict['val_accuracy']\n",
    "plt.plot(val_accuracy_values,'-g',label='val_accuracy')\n",
    "plt.plot(accuracy_values,'-r',label='acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "stru = arg[0]\n",
    "reg = arg[1]\n",
    "tez = arg[2]\n",
    "f = arg[3]\n",
    "model.add(keras.layers.Dense(stru[0], input_shape = (16,), activation = f , kernel_regularizer=keras.regularizers.l2(l=reg)))\n",
    "for i in range(len(stru)-1):\n",
    "    model.add(keras.layers.Dense(stru[i+1], activation = f , kernel_regularizer=keras.regularizers.l2(l=reg)))\n",
    "    b = [tez] * stru[i+1]\n",
    "    w = [b] * stru[i]\n",
    "    w = np.array(w)\n",
    "    b = np.zeros(stru[i+1])\n",
    "    model.layers[i+1].set_weights([w,b])\n",
    "                \n",
    "\n",
    "model.add(keras.layers.Dense(26, activation = \"softmax\"))     \n",
    "model.compile(optimizer = \"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "hist = model.fit(x_train, y_train, epochs = 1700, validation_split = 0.15, batch_size = 700, verbose = 0)\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict=hist.history\n",
    "\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values=history_dict['val_loss']\n",
    "plt.figure()\n",
    "plt.figure()\n",
    "plt.plot(loss_values,'b',label='training loss')\n",
    "plt.plot(val_loss_values,'r',label='val training loss')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_values = history_dict['accuracy']\n",
    "val_accuracy_values=history_dict['val_accuracy']\n",
    "plt.plot(val_accuracy_values,'-g',label='val_accuracy')\n",
    "plt.plot(accuracy_values,'-r',label='acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(x_train)\n",
    "conf_y = []\n",
    "conf_p = []\n",
    "y_train = np.array(y_train)\n",
    "for i in range(len(predict)):\n",
    "    conf_p.append(np.argmax(predict[i], axis=None, out=None))\n",
    "    conf_y.append(np.argmax(y_train[i], axis=None, out=None))\n",
    "    \n",
    "conf_y = np.array(conf_y)\n",
    "conf_p = np.array(conf_p)\n",
    "\n",
    "confusion = tf.math.confusion_matrix(conf_y, conf_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = np.array(confusion)\n",
    "np.set_printoptions(linewidth=np.inf)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(x_test)\n",
    "conf_y = []\n",
    "conf_p = []\n",
    "y_test = np.array(y_test)\n",
    "for i in range(len(predict)):\n",
    "    conf_p.append(np.argmax(predict[i], axis=None, out=None))\n",
    "    conf_y.append(np.argmax(y_train[i], axis=None, out=None))\n",
    "    \n",
    "conf_y = np.array(conf_y)\n",
    "conf_p = np.array(conf_p)\n",
    "\n",
    "confusion = tf.math.confusion_matrix(conf_y, conf_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = np.array(confusion)\n",
    "np.set_printoptions(linewidth=np.inf)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
